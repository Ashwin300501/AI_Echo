# ğŸ§  AI Echo â€” ChatGPT Review Sentiment Dashboard

AI Echo is a **Streamlit-based interactive dashboard** that analyzes ChatGPT user reviews using a **fine-tuned DistilBERT model**.  
It predicts **Positive**, **Neutral**, or **Negative** sentiment directly from review text and visualizes insights across time, user groups, and versions.

---

## ğŸš€ Project Overview

### ğŸ¯ Objective
To build a complete **end-to-end NLP pipeline** for ChatGPT user review analysis:
1. Clean and preprocess textual reviews  
2. Train a Transformer-based model for sentiment classification  
3. Evaluate performance using standard metrics and confusion matrix  
4. Deploy a Streamlit dashboard for real-time predictions and insights  

---

## ğŸ§© Architecture

```text
ğŸ“ AI_Echo/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chatgpt_style_reviews_dataset.xlsx         â† raw dataset
â”‚   â””â”€â”€ clean/reviews_clean.parquet                â† preprocessed dataset
â”‚
â”œâ”€â”€ eda/
â”‚   â””â”€â”€ plots/                                    â† saved EDA visualizations
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ distilbert_sentiment/                      â† fine-tuned DistilBERT model
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚       â”œâ”€â”€ tokenizer.json / tokenizer_config.json
â”‚       â””â”€â”€ special_tokens_map.json
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ phase1_config.json
â”‚   â”œâ”€â”€ cm_distilbert_binary.png                   â† confusion matrix
â”‚   â””â”€â”€ phase2_metrics_distilbert_binary.json      â† model performance metrics
â”‚
â”œâ”€â”€ app.py                                         â† Streamlit app (model-only)
â”œâ”€â”€ README.md
â””â”€â”€requirements.txt
```

---

## âš™ï¸ Workflow Summary

### **1ï¸âƒ£ Data Preprocessing**
- Removed punctuation, URLs, mentions, emojis, and stopwords  
- Applied lemmatization using NLTK  
- Created derived features:
  - `review_length`
  - `review_tokens`
  - `month`, `week`, `verified_purchase`, etc.  
- Saved cleaned dataset as `reviews_clean.parquet`

### **2ï¸âƒ£ EDA**
Visualized rating distributions and patterns:
- Rating frequency  
- Word clouds for positive/negative reviews  
- Average rating over time  
- Verified vs Non-Verified comparison  
- Location and version insights  

### **3ï¸âƒ£ Model Training (DistilBERT)**
- Used HuggingFace `transformers` for fine-tuning  
- Removed oversampling for neutral reviews  
- Dataset balanced only between positive and negative classes where necessary  
- Config:
  ```python
  learning_rate = 2e-5
  batch_size = 16
  epochs = 3
  model = "distilbert-base-uncased"
  ```
- Metrics used:
  - Accuracy  
  - F1-score (Weighted & Binary)  
  - Confusion Matrix  

### **4ï¸âƒ£ Dashboard (Streamlit)**
- **Tab 1: ğŸ’¬ Sentiment Prediction**
  - Enter custom reviews and get real-time predictions from DistilBERT  
  - Visualize model confidence scores  
  - Displays overall sentiment distribution (model predictions)

- **Tab 2: ğŸ“Š Key Questions for Sentiment Analysis**
  - Overall sentiment distribution  
  - Sentiment vs rating mismatch  
  - Word clouds for each sentiment class  
  - Sentiment trends over time  
  - Verified user sentiment patterns  
  - Review length vs sentiment  
  - Location and platform breakdowns  
  - Version impact on sentiment  
  - Common themes in negative reviews  

---

## ğŸ§  Model Details

| Component | Description |
|------------|-------------|
| **Base Model** | DistilBERT (base uncased) |
| **Task** | Multi-class Sentiment Classification (3 classes) |
| **Labels** | Negative / Neutral / Positive |
| **Tokenizer** | DistilBertTokenizerFast |
| **Optimizer** | AdamW |
| **Evaluation Metric** | F1-weighted, Accuracy |

---

## ğŸ§¾ Example Outputs

### ğŸ”¹ Confusion Matrix
Saved at `artifacts\cm_distilbert_3class.png`

### ğŸ”¹ Evaluation Metrics
| Metric | Score |
|---------|-------|
| **Accuracy** | ~0.44 |
| **Weighted F1-Score** | ~0.38 |

Confusion Matrix example:  
![Confusion Matrix](artifacts\cm_distilbert_3class.png)

---

## ğŸ“¦ Artifacts & Outputs

| File | Description |
|------|--------------|
| `data/clean/reviews_clean.parquet` | Cleaned review data |
| `artifacts/phase1_config.json` | Phase 1 configuration metadata |
| `artifacts/phase2_metrics_distilbert_binary.json` | Model performance metrics |
| `artifacts/cm_distilbert_binary.png` | Confusion matrix visualization |
| `eda/plots/` | Word clouds, rating trends, etc. |

---

## ğŸš« Model Files Note

The trained DistilBERT weights are **not included** due to GitHubâ€™s 100 MB limit.

You can load the model from Hugging Face:
```
Ashwin20015/ai-echo-distilbert-sentiment
```
Or place your own trained model under:
```
models/distilbert_sentiment/
```
3. The app will automatically detect and use it for inference.

---

## ğŸ’¡ Key Insights

- Positive reviews emphasize *ease of use*, *creativity*, and *accuracy*.  
- Negative reviews frequently mention *hallucinations*, *incorrect answers*, and *slow response*.  
- Verified users tend to leave more positive reviews.  
- Sentiment improves with later ChatGPT versions.  
 
